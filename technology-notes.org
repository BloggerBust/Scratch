* Node
- process.env.NODE_ENV :: environment variable for configuring what environment node should run in i.e. dev, prod etc.
** npm
   - node package-manager
   - npm help <command> :: brings up help documentation on the specified command
** Node Modules
*** Bower
  - Install: $npm install -g bower
  - Help:
    - $ bower help
    - help on specific command : $ bower help command_name
  - Bower Lookup:
   Lets you see the git uri for a specific package
    - $bower lookup lodash
  - Bower Install: 
    - current version: $ bower install lodash
    - specific version: $ bower install lodash#2.2.1
    - save package to bower.json dependencies: $ bower install lodash --save
    - install package to dev only: $ bower install lodash --save-dev
    - install from cache (offline mode): $ bower install lodash -o
    - install from local repository: $ bower install relative-path/ProjectDirectoryName
    - install regular dependencies: $ bower install --production
    - install to named folder: $ bower install named_dir=lodash
  - Bower Uninstall: 
    - $ bower uninstall lodash
    - $ Remove from dependencies: bower uninstall lodash --save 
    - $ Remove from dev dependencies: bower uninstall lodash --save-dev
  - Bower Package Info: $ bower info lodash
  - Bower Update:
    - Update all packages: $bower update
    - Update single package: Just use Bower Install. It will update already installed packages.
  - Bower List:
    - list already installed packages: $bower list
  - Prune:
    Removes all packages that are not indicated in the bower.json file or are not sub-dependencies of existing dependencies.
    - $ bower prune
  - Bower Registery Search:
    - find all packages with the specified word: $bower search lodash
    - find package by keyword: go to the bower site http://bower.io/search/
  - Bower Init:
    - Used to create the bower json file: $ bower init
  - Bower RC:
    - Create a file called .bowerrc that contains a json with a single property named "directory"
      {
        "directory": "js/lib"
      }
      This specifies where bower should install packages.
    - Have bower install to more than one directory by creating more than one init point. So you could have a sub directory called test and throw a bower.json and .bowerrc file in there for managing dependencies in directory test/js/lib.
  - Bower Cache
    - List what is in the cache: $bower cache list
    - Clean the cache: $bower cache clean
  - Bower register
    To register a repository
    - $ git register https://github.com/TrevorWilsonSS/[reponame]
    - It will then ask if it can register the package with bower.herokuapp.com.
*** nodemon
    - Run a node application reloads modified files on the fly.
    - usage :: $ nodemon main-file.js
*** Stylus
    - A CSS preprocessor
    - styl :: file extension
*** Jade
  - The view engine used by express applications
  - jade :: file extension
  - doctype :: specifies that the jade file will contain HTML5
  - // :: a single line comment
*** toastr
*** ExpressJS
*** Morgan
    - Http request logger middleware
*** Body-parser
    - Body parser middleware
*** Mongoose
  - Fascilitates implementation of mongo-db in node applications
  - makes implementation of mongo much easier.
  - works off of schemas. Since mongo-db is a schema list document database, implementing schemas with mongoose is often seen as a bad idea.
    
* Angular JS
** Isolate Scope
- Local Scope Properties: Used to allow information flow between isolate and parent scope. Note that the alternate name option applies to all local scope properties, but is only illustrated with the @ below.
  - @: one-way binding of string values
    - directive usage:
      scope: {
    name: '@'
    value: '@someOtherAttrName'
    }
    - consumer usage:
    <div my-isolate-scope-with-name name: '{{customer.name}}' someOtherAttrName='{{constomer.value}}'></div>
  - =: two-way binding of objects
    - directive usage:
   scope: {
   customer: '='    
   },
    template: '<ul><li ng-repeat="prop in customer">{{prop}}</li></ul>
    - consumer usage:
      <div my-isolate-scope-with-model customer="customer"></div>
  - &: function binding for call-backs
    - directive usage:
      scope{
      action:'&'
      }
    - consumer usage:
      <div my-isolate-scope-with-function action="doStuff()" />
* Mongo-db
  - A schema list document database
  - No schema to define.
  - No relationship between collections of objects.
  - Objects can be flat or structured.
  - Two documents in same collection can be different from each other since no schema governs the collection.
    + Scalability
      - Single document write scope. Documents live in a collection, but updating a document occurs one at a time.
      - No need to extend locks accross collections because there are no relationships to enforce.
      - Eventual consistency. Mongo does not lock accross multiple mongo servers. A repleca set in mongo contains a single server that will handle all writes and a collection of secondary servers that will be replecated to. There is a lag of time from when a write occurs in the Primary DB to when the value is made observable by others by being replicated in a secondary db; hence, eventual consistancy.
      - Can choose consistancy model: 
        - Can choose to wait for primary write server to persist data
        - To wait for all replica servers to sync with the primary server following the write.
        - To wait for a majority of replica servers to sync with the primary server following the write.
        - Choose to hand over document to primary and not care wether it persisted or not.
      - Capped Collections:
        - Fixed size :: no time to allocate space
        - Auto override all documents
    + Mongod
      - The daemon.
      - Default Port: 27017
      - mongod help :: help documentation for commandline options
    + Mongos
      - The sharding server.
  - Mongo Client
    - mongo :: starts the client
    - help :: brings up client help documentation
    - exit :: quits the client
    - show dbs :: lists existing dbs
    - db :: shows the current database
    - use foo :: switches to database few and creates it if it does not exist.
    - db.getMongo() :: returns host and port for that server instance.
  - Replica Sets
    - Advantages :: scalability and automatic recovery.
    - Types :: Primary, Secondary, Arbiter
    - Primary
      - One and only primary instance. 
    - Secondary
      - Readonly
      - one to many
      - Data is replicated from primary. Gaurantees eventual consistancy.
      - If Primary database fails, one of the seconary databases will take over and become the primary. This is descided by an election.
      - Nothing special happens if a secondary db fails. If one secondary fails and there are others than no big deal. Haveing multiple Secondaries protects against single server failure.
    - Arbiter
      - sole purpose is to break ties on primary db elections.
      - is not a database. It contains no data.
    - Minimal replica set :: Primary DB, 1 Secondary DB, 0 or 1 Arbiters
    - Dev can run a replica set on a single machine. Production should run each mongo server per machine
    - Creation of single machine replica set:
      - Each mongo server requires its own db directory. i.e. db{1,2,3}
      - Each mongo server must run on a different port
      - mongod --dbpath ./db{n} --port unique_port_num --replSet "<replicaSetName>"
** TODO Install Mongo-db Minimal ReplicaSet
   - mongod -f "e:\dev\experiments\MultiVision\conf\mongod1.conf" --replSet "Experiments" --install
   - Windows instructions to get the replica set running as a service.
* jquery
* git
** Steps to create a new Github Rep
 1. Login to github and create the repository
 2. Copy the ssh path to the new repository
 3. Follow this command pattern:
    - $ mkdir myProj
    - $ cd myProj
    - $ git init
    - touch README.md
    - touch .gitignore
    - git add -A
    - git commit -m "my first checkin"
    - git remote add origin [paste copied git repo uri here]
    - git push -u origin master :: //MUST BE IN INTERACTIVE SHELL TO PROVIDE CREDENTIALS
    
** Steps to tag and push a new release
 1. cd myProj
 2. command pattern:
    - git tag 0.0.1 :: Should be the same version as entered in bower.json "version" property
    - git push --tags
 3. Now visit github, click on the project and then click on the release link to view the release.

* Linux 
** Commands :: remember to always check the man pages.
  - lsblk :: list block devices.
  - lddtree --help :: there are no man pages for this command
  - lddtree --copy-to-tree=/source/path /target/path :: from app-misc/pax-utils USE="python"
  - find /usr/portage -name '*.ebuild' -o -name '*.eclass' | xargs grep MAKE_CONF_VARIABLE :: finds all package references to MAKE_CONF_VARIABLE
  - lspci | grep -i vga :: detect video controller
*** Detect Motherboard, Bios and CPU
   - dmidecode -t 4 | grep ID :: The CPU ID
   - dmidecode -t 0 :: Bios info
   - dmidecode -t 4 :: Processor info
   - dmidecode -t 11 :: Original Equipment Manufacturer (OEM) info
** I/O Stream Numbers
   | Handle | Name   | Description     |
   |      0 | stdin  | Standard input  |
   |      1 | stdout | Standard output |
   |      2 | stderr | Standard error  |
   - =$ program-name 2> error.log= :: Redirect standard error stream to a file
   - =$ program-name &>file= :: Redirect the standard error (stderr) and stdout to file
     =$ program-name > file-name 2>&1= :: Alternate redirect the standard error (stderr) and stdout to file

** Boot Process
  1. Boot loader loads Linux.
  2. Linux assumes control of the system.
  3. Linux prepares its memory structures and drivers
  4. Hands control to Init.
  5. Init makes sure that at the end of the boot process, all necessary services are running and the user is able to log in.
  6. Init launches udev daemon which will further load up and prepare the system based on the detected devices.
  7. Udev mounts the remaining file systems waiting to be mounted.
  8. Udev starts the remaining services waiting to be started.
      
** Initramfs
*** The Initial RAM File System
  - Based on tmpfs
  - Because it is a size-flexible, in-memory lightweight file system it does not use a seperate block device so no caching was done. It does not have the overhead of an entire file system.
  - Contains the tools and scripts needed to mount the file systems before the init binary on the real root file system is called.
    - The tools can be the decryption abstraction layers (for encrypted file systems), logical volume mangers, software raid, bluetooth driver based file system loaders, etc.
  - All files, tools, libraries, configuration settings (if applicable), etc are put into a cpio archive.
*** From creation to execution
  1. The cpio archive is compressed using gzip and stored in the /boot partition along side the linux kernel.
  2. The boot loader will let the linux kernel know where the cpio archive is at boot time so that the kernel can load the initramfs.
  3. The Linux kernel will create a tmpfs file system, extract the contents of the cpio archive into it, and then launch the init script located in the root of the tmpfs file system.
  4. The init script will then perform what ever tasks are necessary to ensure that it will be able to mount the real root file system.
    - It may have to decrypt the real root file system, other vital file systems, and mount them among possibly other things depending on what is needed.
  5. The init script from the initramfs will then switch the root towards the real root file system
  6. Lastly the initramfs init script will call /sbin/init (the init script on the real root file system)
  7. The boot process will continue as normal.
** Gentoo
*** Use Variables
    - If a use variable has a * by it that means that it changed since the last build.
*** Hardened Profile
**** PIC (Position Independent Code)
     - Functions and data are accessed through an indirect table called the Global Offset Table (GOT).
     - The purpose of indirect addressing is to fascillitate the access of functions and data independently of the corresponding load address. Only the symbols in the text segment exported in the GOT need updating at run-time deending on the current load address of the various shared libraries in the address space of the running process.
     - Similarly, procedure calls to globally defined functions are redirected through the "Procedure Linkage Table" (PLT) residing in the data segment of the core image. This avoids runtime modifications of the text segment.
     - The Linker-editor allocates the GOT and PLT when combining the PIC object files into an image for mapping into the process address space.
     - The Linker-editor collects all symbols that may be needed by the run-time link-editor and stores these along with the image's text and data bits.
     - Objects compiled as PIC allow the OS to load the object at any address in preperation for execution with slight overhead.
     - The libtool builds PIC objects for use in shared libraries and non-PIC objects for use in static libraries. PIC compilation is required for objects in a shared library.
     - libtool compiles PIC objects with '*.lo' extension and non-PIC objects with '*.o' extension.
     - In practice PIC objects can be linked into static archive and often non-PIC objects can be similarly linked into shared archives both with execution and load speed overhead.
     - If the shared object is built from code that is not PIC then the text segment will usually require a large number of relocations to be performed at runtime. The system overhead from the run-time linker required to handle this can cause serious performance degradation.
     - =# readelf -d foo= :: If the output contains a TEXTREL entry then text relocations exist.
**** PaX
     - Purpose is to protect against a class of exploits that give an attacker arbitrary read / write access to the attacked task's address space. These exploits include buffer and heap overflows and similar attacks. PaX is the first line of defense offered by Hardened Gentoo.
     - Implements the least privilege protections for memory pages. i.e computer programs should only  be allowed to do what they have to do in order to be able to execute properly and nothing more.
     - The exploit techniques that PaX defends against include:
       1. Introduce / execute arbitrary code
       2. execute existing code out of original program order
       3. execute existing code in original program order with arbitrary data
     - References:
       - Gentoo Hardened Introduction :: https://wiki.gentoo.org/wiki/Hardened/Introduction_to_Hardened_Gentoo#Technologies_Offered
       - Project site :: http://pax.grsecurity.net/
       - Quickstart :: https://wiki.gentoo.org/wiki/Hardened/PaX_Quickstart
     - Adds security enhancement to the area between both kernel and userland.
     - Patch to the kernel that provides hardening in the following ways:
       1. Judicious enforcement of non-executable memory
       2. Address Space Layout Randomization (ASLR)
          - Compiling with Position Independent Executable (PIE) allows ASLR to randomaize even the base address.
       3. Miscellaneous hardening on stack and memory handling
          - Erases stack frame when returning from a system call
          - refusing to dereference user-land pointers in some context
          - detecting overflows of certain reference counters
          - correcting overflows of some integer counters
          - enforcing the size on copies between kernel and user land
          - providing extra entropy
     - PaX Modes
       - SOFTMODE
         - PaX protection will not be enforced by default for those features which can be turned on or off at runtime.
         - The "permit by default" mode.
         - The user must explicitly mark executables to enforce PaX protection.
       - non-SOFTMODE
         - PaX protections are immediately activated.
         - The "forbid by default" mode.
         - The user must explicitly mark binaries to relax PaX protection selectively.
       - 
* TODO [/] Work emacs init.el
  [ ] Install helm package
  [ ] Install omnisharp https://github.com/OmniSharp/omnisharp-emacs
